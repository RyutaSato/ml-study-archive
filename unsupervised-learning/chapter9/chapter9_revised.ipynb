{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import *\n",
    "print_version()\n",
    "cfg = load_config('default')\n",
    "random_seed = cfg['random_seed']\n",
    "tf.random.set_seed(cfg['tf_seed'])\n",
    "np.random.seed(cfg['np_seed'])\n",
    "data_x, data_y = load_credit_card_dataset()\n",
    "scaled_x = standard_scale(data_x)\n",
    "\n",
    "test_split_clm = load_config(\"supervised.test_split\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled_x, data_y, stratify=data_y, **test_split_clm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Number of negative and positive examples\n",
    "np.sum(y_train==0),np.sum(y_train==1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 訓練セットの90％をDrop\n",
    "drop_idx = y_train[y_train==1].sample(frac=0.90, random_state=random_seed).index\n",
    "x_train.drop(labels=drop_idx, inplace=True)\n",
    "y_train.drop(labels=drop_idx, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shape of data\n",
    "print([each.shape for each in (x_train, x_test, y_train, y_test)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check the number of fruadulant cases left after dropping 90%\n",
    "np.sum(y_train==0),np.sum(y_train==1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 9.2 教師ありモデル\n",
    "\n",
    "# k分割交差検証\n",
    "k_fold_prm = load_config('supervised.k_fold')\n",
    "#　k-foldは，`StratifiedKFold`　を使用しているため，y_trainのラベル分布が近くなるように分割する．\n",
    "k_fold = StratifiedKFold(**k_fold_prm)\n",
    "predictions_based_on_k_folds = pd.DataFrame(\n",
    "    data=[], index=y_train.index, columns=['prediction']\n",
    ")\n",
    "# 学習\n",
    "training_scores = [] # 学習率\n",
    "validation_scores = [] # 検証スコア\n",
    "\n",
    "# x_trainの値の分布を考慮せずに分割して欲しいため，0埋めした配列を`split()`の引数にいれ，そのランダムなインデックスのリストを取得する．\n",
    "for train_idx, validation_idx in k_fold.split(np.zeros(len(x_train)), y_train.ravel()):\n",
    "    x_train_fold, x_validation_fold = x_train.iloc[train_idx, :], x_train.iloc[validation_idx, :] # 2次元配列\n",
    "    y_train_fold, y_validation_fold = y_train.iloc[train_idx], y_train.iloc[validation_idx] # １次元配列\n",
    "\n",
    "    lgb_train = lgb.Dataset(x_train_fold, y_train_fold)\n",
    "    lgb_eval = lgb.Dataset(x_validation_fold, y_validation_fold, reference=lgb_train)\n",
    "    lgb_params = load_config('supervised.lgb')\n",
    "    gbm = lgb.train(lgb_params, lgb_train,\n",
    "                         num_boost_round=2000,\n",
    "                         valid_sets=lgb_eval,\n",
    "                         callbacks=[lgb.early_stopping(200)]\n",
    "                         )\n",
    "\n",
    "    y_train_predict = gbm.predict(x_train_fold, num_iteration=gbm.best_iteration)\n",
    "    training_score = log_loss(y_train_fold, y_train_predict)\n",
    "\n",
    "    y_validation_predict = gbm.predict(x_validation_fold, num_iteration=gbm.best_iteration)\n",
    "    predictions_based_on_k_folds.loc[x_validation_fold.index, 'prediction'] = y_validation_predict\n",
    "    validation_score = log_loss(y_validation_fold, y_validation_predict)\n",
    "\n",
    "\n",
    "    print(f\"training log loss:  {training_score}\")\n",
    "    print(f\"validation log loss: {validation_score}\")\n",
    "    training_scores.append(training_score)\n",
    "    validation_scores.append(validation_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_loss_light_gbm_gradient_boosting = log_loss(y_train, predictions_based_on_k_folds.loc[:, 'prediction'])\n",
    "print(f'Light GBM Gradient Boosting Log loss: {log_loss_light_gbm_gradient_boosting}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, average_precision = plot_results(y_train, predictions_based_on_k_folds.loc[:,'prediction'], True)\n",
    "print(f\"average_precision: {average_precision}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate on Test Set\n",
    "predictions = pd.Series(data=gbm.predict(x_test,\n",
    "                                         num_iteration=gbm.best_iteration), index=x_test.index)\n",
    "preds, average_precision = plot_results(y_test, predictions, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate precision at 75% recall\n",
    "preds, precision = precision_analysis(preds, \"anomaly_score\", 0.75)\n",
    "print(f'Precision at 75% recall {round(precision,4)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 9.3 教師なしモデル\n",
    "over_sample_multiplier: int = load_config('unsupervised.over_sample_multiplier')\n",
    "x_train_oversampled = x_train.copy()\n",
    "y_train_oversampled = y_train.copy()\n",
    "x_train_oversampled = x_train_oversampled.append([x_train_oversampled[y_train==1]] * over_sample_multiplier, ignore_index=False)\n",
    "y_train_oversampled = y_train_oversampled.append([y_train_oversampled[y_train==1]] * over_sample_multiplier, ignore_index=False)\n",
    "# View shape\n",
    "x_train_oversampled.shape, y_train_oversampled.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(units=40, activation='linear', activity_regularizer=regularizers.l1(10e-5), input_dim=29, name='hidden_layer'),\n",
    "    Dropout(0.02),\n",
    "    Dense(units=29, activation='linear')\n",
    "])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compile_prm = load_config('unsupervised.compile')\n",
    "model.compile(**compile_prm)\n",
    "fit_prm = load_config('unsupervised.fit')\n",
    "x_illegal = x_train_oversampled[y_train_oversampled==0]\n",
    "history = model.fit(x=x_illegal, y=x_illegal, **fit_prm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_illegal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_train = model.predict(x_train, verbose=1)\n",
    "annomaly_scores_ae_train = anomaly_scores(x_train, predictions_train)\n",
    "preds, average_precision = plot_results(y_train, annomaly_scores_ae_train, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "annomaly_scores_ae_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "predictions = model.predict(x_test, verbose=1)\n",
    "anomaly_scores_ae = anomaly_scores(x_test, predictions)\n",
    "preds, average_precision = plot_results(y_test, anomaly_scores_ae, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate precision at 75% recall\n",
    "preds, precision = precision_analysis(preds, \"anomaly_score\", 0.75)\n",
    "print(f'Precision at 75% recall {round(precision,4)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 9.4 半教師ありモデル\n",
    "\n",
    "# 入力が29，出力が40\n",
    "intermediate_model = keras.Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(\"hidden_layer\").output)\n",
    "intermediate_output_train = intermediate_model.predict(x_train)\n",
    "intermediate_output_test = intermediate_model.predict(x_test)\n",
    "\n",
    "intermediate_output_train_df = pd.DataFrame(data=intermediate_output_train, index=x_train.index)\n",
    "intermediate_output_test_df = pd.DataFrame(data=intermediate_output_test, index=x_test.index)\n",
    "\n",
    "# with_ae は元のデータセットの２９個の特徴量と，オートエンコーダ由来の４０個の表現を併せ持つ\n",
    "x_train_with_ae = x_train.merge(intermediate_output_train_df, left_index=True, right_index=True)\n",
    "x_test_with_ae = x_test.merge(intermediate_output_test_df, left_index=True, right_index=True)\n",
    "y_train_with_ae = y_train.copy()\n",
    "x_train_with_ae.shape, y_train_with_ae.shape, x_train_with_ae.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 学習\n",
    "training_scores = [] # 学習率\n",
    "validation_scores = [] # 検証スコア\n",
    "\n",
    "predictions_based_on_k_folds = pd.DataFrame(\n",
    "    data=[], index=y_train_with_ae.index, columns=['prediction']\n",
    ")\n",
    "for train_idx, validation_idx in k_fold.split(np.zeros(len(x_train_with_ae)), y_train_with_ae.ravel()):\n",
    "    x_train_fold, x_validation_fold = x_train_with_ae.iloc[train_idx, :], x_train_with_ae.iloc[validation_idx, :] # 2次元配列\n",
    "    y_train_fold, y_validation_fold = y_train_with_ae.iloc[train_idx], y_train_with_ae.iloc[validation_idx] # １次元配列\n",
    "\n",
    "    lgb_train = lgb.Dataset(x_train_fold, y_train_fold)\n",
    "    lgb_eval = lgb.Dataset(x_validation_fold, y_validation_fold, reference=lgb_train)\n",
    "    lgb_params = load_config('supervised.lgb')\n",
    "    gbm = lgb.train(lgb_params, lgb_train,\n",
    "                    num_boost_round=2000,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    callbacks=[lgb.early_stopping(200)]\n",
    "                    )\n",
    "\n",
    "    y_train_predict = gbm.predict(x_train_fold, num_iteration=gbm.best_iteration)\n",
    "    training_score = log_loss(y_train_fold, y_train_predict)\n",
    "\n",
    "    y_validation_predict = gbm.predict(x_validation_fold, num_iteration=gbm.best_iteration)\n",
    "    predictions_based_on_k_folds.loc[x_validation_fold.index, 'prediction'] = y_validation_predict\n",
    "    validation_score = log_loss(y_validation_fold, y_validation_predict)\n",
    "\n",
    "\n",
    "    print(f\"training log loss:  {training_score}\")\n",
    "    print(f\"validation log loss: {validation_score}\")\n",
    "    training_scores.append(training_score)\n",
    "    validation_scores.append(validation_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print results\n",
    "log_loss_light_gbm_gradient_boosting = log_loss(y_train_with_ae, predictions_based_on_k_folds.loc[:,'prediction'])\n",
    "print(f'LightGBM Gradient Boosting Log Loss: {round(log_loss_light_gbm_gradient_boosting, 4)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds, average_precision = plot_results(y_train_with_ae, predictions_based_on_k_folds.loc[:,'prediction'], True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate results on test set\n",
    "predictions = pd.Series(data=gbm.predict(x_test_with_ae, num_iteration=gbm.best_iteration),index=x_test_with_ae.index)\n",
    "preds, average_precision = plot_results(y_test, predictions, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate precision at 75% recall\n",
    "preds, precision = precision_analysis(preds, \"anomaly_score\", 0.75)\n",
    "print(f'{round(precision,4)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Analyze most important features\n",
    "featuresImportance = pd.DataFrame(data=list(gbm.feature_importance()), index=x_train_with_ae.columns,columns=['featImportance'])\n",
    "featuresImportance = featuresImportance/featuresImportance.sum()\n",
    "featuresImportance.sort_values(by='featImportance', ascending=False,inplace=True)\n",
    "featuresImportance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print([each.shape for each in (x_train, x_test, y_train, y_test)])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
