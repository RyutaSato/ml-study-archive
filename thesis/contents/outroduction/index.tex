\chapter{おわりに}
\section{本研究のまとめ}
本研究では，不均衡データに対する特徴量拡張手法として，オートエンコーダを用いた特徴量拡張手法を提案した．本手法では，入力データを学習したオートエンコーダのエンコーダ部分からの出力をAE特徴量と定義し，用意した30通りのデータセットに対して，特徴量拡張を行うったモデルと行わなかったモデルを比較した．また，それらのモデルの中でも，前処理をしないモデル，標準化したモデル，正規化したモデルの3つのモデル，さらにAE特徴量に対する前処理の有無，オートエンコーダの構成，学習する機械学習モデル，ハイパーパラメータチューニングの有無等，様々な条件で特徴量拡張の有効性について検証を行った．\\
その結果，特に前処理として，入力データおよびAE特徴量に対し，標準化を適用し特徴量拡張を行い，多数派クラスのみで構築したオートエンコーダを用いたモデルが，拡張しなかったモデルよりも高い精度を出した．以上から，オートエンコーダを用いた特徴量拡張が有用であることを示した．

\section{今後の課題}
今後取り組める課題としては以下のものがある．
\begin{itemize}
    \item オートエンコーダの構成を変えた場合の精度の比較\\
    今回の実験では，変えなかったオートエンコーダのエポック数，バッチサイズ，活性化関数，最適化関数によっても生成されるAE特徴量が異なる可能性がある．また，今回は３通りしかオートエンコーダの構成を変えなかったが，より精度の高い構成がある可能性がある．
    \item 全てのケースでのハイパーパラメータチューニング\\
    本実験では，時間的・計算資源的リソースの都合上全てのケースでのハイパーパラメータチューニングを用いた実験を終えることができなかった．今後は，全てのケースでのハイパーパラメータチューニングを行い，より精度の高いモデルを構築することで，よりAE特徴量の有効性を示すことができる可能性がある．
    \item 特徴量拡張が有用となる要件の発見\\
    特徴量数や，サンプル数に着目して，精度が上がったデータセットの共通点，逆に精度が下がったデータセットの共通点を探してみたが，特に明確な傾向は見られなかった．今後は，別の視点や別のデータセットで試すことでより有用な特徴量拡張手法を提案することができる可能性がある．

\end{itemize}