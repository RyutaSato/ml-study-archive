{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:53:44.682213Z",
     "start_time": "2023-07-18T00:53:25.902658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徴量の数：41\n",
      "各特徴量の名前：duration, protocol_type, service, flag, src_bytes, dst_bytes, land, wrong_fragment, urgent, hot, num_failed_logins, logged_in, num_compromised, root_shell, su_attempted, num_root, num_file_creations, num_shells, num_access_files, num_outbound_cmds, is_host_login, is_guest_login, count, srv_count, serror_rate, srv_serror_rate, rerror_rate, srv_rerror_rate, same_srv_rate, diff_srv_rate, srv_diff_host_rate, dst_host_count, dst_host_srv_count, dst_host_same_srv_rate, dst_host_diff_srv_rate, dst_host_same_src_port_rate, dst_host_srv_diff_host_rate, dst_host_serror_rate, dst_host_srv_serror_rate, dst_host_rerror_rate, dst_host_srv_rerror_rate\n",
      "smurf              2807886\n",
      "neptune            1072017\n",
      "normal              972781\n",
      "satan                15892\n",
      "ipsweep              12481\n",
      "portsweep            10413\n",
      "nmap                  2316\n",
      "back                  2203\n",
      "warezclient           1020\n",
      "teardrop               979\n",
      "pod                    264\n",
      "guess_passwd            53\n",
      "buffer_overflow         30\n",
      "land                    21\n",
      "warezmaster             20\n",
      "imap                    12\n",
      "rootkit                 10\n",
      "loadmodule               9\n",
      "ftp_write                8\n",
      "multihop                 7\n",
      "phf                      4\n",
      "perl                     3\n",
      "spy                      2\n",
      "Name: true_label, dtype: int64\n",
      "(4898431, 38)\n"
     ]
    },
    {
     "data": {
      "text/plain": "dos       3883370\nnormal     972781\nprobe       41102\nr2l          1126\nu2r            52\nName: true_label, dtype: int64"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils_kdd99 import *\n",
    "data_x, data_y = load_data(use_full_dataset=True)\n",
    "\n",
    "# 4つのクラスラベルに変換する\n",
    "data_y = data_y.map(lambda x: attack_label_class[x])\n",
    "data_y.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 3281948, x_test: 1616483\n",
      "y_train\n"
     ]
    },
    {
     "data": {
      "text/plain": "dos       2601857\nnormal     651763\nprobe       27538\nr2l           755\nu2r            35\nName: true_label, dtype: int64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# data_y = pd.get_dummies(data_y)\n",
    "# データを分割する。テストと，学習の比は1：2なるようにします。\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.33, random_state=RANDOM_SEED, stratify=data_y)\n",
    "print(f\"x_train: {len(x_train)}, x_test: {len(x_test)}\")\n",
    "print(f'y_train')\n",
    "y_train.value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:53:49.074884Z",
     "start_time": "2023-07-18T00:53:44.712858Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test\n"
     ]
    },
    {
     "data": {
      "text/plain": "dos       1281513\nnormal     321018\nprobe       13564\nr2l           371\nu2r            17\nName: true_label, dtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'y_test')\n",
    "y_test.value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:53:49.156246Z",
     "start_time": "2023-07-18T00:53:49.107639Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "1537115    0\n4657510    0\n1894345    0\n1649777    0\n1634756    0\nName: true_label, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 目的変数を数値に変換\n",
    "correspondences = {\n",
    "    'dos': 0,\n",
    "    'normal': 1,\n",
    "    'probe': 2,\n",
    "    'r2l': 3,\n",
    "    'u2r': 4\n",
    "}\n",
    "y_train = y_train.map(lambda x: correspondences[x])\n",
    "y_test = y_test.map(lambda x: correspondences[x])\n",
    "y_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:53:49.843552Z",
     "start_time": "2023-07-18T00:53:49.111796Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satun/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_error: 0.000460258\n"
     ]
    },
    {
     "data": {
      "text/plain": "0    1281353\n1     320899\n2      13510\n3        482\n4        239\ndtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    "\n",
    "# LightGBM parameters\n",
    "params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 5,\n",
    "        'metric': {'multi_error'}, # 評価指標 : 誤り率(= 1-正答率)  another multi_logloss\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 23,\n",
    "        'min_data_in_leaf': 1,\n",
    "        'num_iteration': 1000, #1000回学習\n",
    "        'verbose': 0\n",
    "}\n",
    "\n",
    "# モデルの学習\n",
    "model = lgb.train(params, # パラメータ\n",
    "            train_set=lgb_train, # トレーニングデータの指定\n",
    "            valid_sets=lgb_eval, # 検証データの指定\n",
    "            callbacks=[lgb.early_stopping(100)]\n",
    "               )\n",
    "\n",
    "# テストデータの予測 (クラス1の予測確率(クラス1である確率)を返す)\n",
    "y_pred_prob = model.predict(x_test)\n",
    "# テストデータの予測 (予測クラスを返す)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1) # 一番大きい予測確率のクラスを予測クラスに\n",
    "y_pred = pd.Series(y_pred)\n",
    "y_pred.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:54:20.233960Z",
     "start_time": "2023-07-18T00:53:49.845640Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dos       1.00      1.00      1.00   1281513\n",
      "      normal       1.00      1.00      1.00    321018\n",
      "       probe       1.00      0.99      0.99     13564\n",
      "         r2l       0.73      0.95      0.83       371\n",
      "         u2r       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           1.00   1616483\n",
      "   macro avg       0.75      0.79      0.76   1616483\n",
      "weighted avg       1.00      1.00      1.00   1616483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=correspondences.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:54:21.460893Z",
     "start_time": "2023-07-18T00:54:20.237175Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dos    TP: 1281328, TN: 334945, FP: 185, FN: 25\n",
      "normal    TP: 320603, TN: 1295169, FP: 415, FN: 296\n",
      "probe    TP: 13454, TN: 1602863, FP: 110, FN: 56\n",
      "r2l    TP: 354, TN: 1615984, FP: 17, FN: 128\n",
      "u2r    TP: 0, TN: 1616227, FP: 17, FN: 239\n"
     ]
    }
   ],
   "source": [
    "for key, confusion_matrix in zip(correspondences.keys(), multilabel_confusion_matrix(y_test, y_pred)):\n",
    "    print(f\"{key}    TP: {confusion_matrix[1][1]}, TN: {confusion_matrix[0][0]}, FP: {confusion_matrix[1][0]}, FN: {confusion_matrix[0][1]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:54:21.645544Z",
     "start_time": "2023-07-18T00:54:21.461956Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder1 (Dense)            (None, 19)                741       \n",
      "                                                                 \n",
      " encoder2 (Dense)            (None, 10)                200       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 19)                209       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 38)                760       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,910\n",
      "Trainable params: 1,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(units=19, activation='relu', input_dim=38, name='encoder1'),\n",
    "    Dense(units=10, activation='relu', name='encoder2'),\n",
    "    Dense(units=19, activation='relu'),\n",
    "    Dense(units=38, activation='relu'),\n",
    "])\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:54:21.783138Z",
     "start_time": "2023-07-18T00:54:21.678410Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 09:54:23.203821: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102561/102561 [==============================] - 89s 860us/step - loss: 0.6288 - accuracy: 0.1961 - val_loss: 0.6018 - val_accuracy: 0.2068\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x15b3c49a0>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.fit(x_train, x_train,\n",
    "          epochs=1, # データセットを使って学習する回数\n",
    "        batch_size=32,\n",
    "        shuffle=True, # データをシャッフルすることで，．\n",
    "        validation_data=(x_train, x_train), # 評価用データ（検証データ）の指定\n",
    "        verbose=1,\n",
    "        use_multiprocessing=True\n",
    "          )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:55:52.064422Z",
     "start_time": "2023-07-18T00:54:21.787373Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50516/50516 [==============================] - 13s 255us/step\n"
     ]
    }
   ],
   "source": [
    "x_pred = model.predict(x_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:56:14.338026Z",
     "start_time": "2023-07-18T00:55:52.145238Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "encoder = keras.Sequential([model.get_layer('encoder1'),\n",
    "                            model.get_layer('encoder2')])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:56:14.346667Z",
     "start_time": "2023-07-18T00:56:14.339624Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102561/102561 [==============================] - 24s 231us/step\n",
      "50516/50516 [==============================] - 12s 232us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "         duration  src_bytes  dst_bytes      land  wrong_fragment    urgent  \\\n1537115 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n4657510 -0.066833  -0.001949  -0.001696 -0.002391       -0.015139 -0.001103   \n1894345 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n1649777 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n1634756 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n...           ...        ...        ...       ...             ...       ...   \n2391255 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n2471385 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n2676542 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n1475808 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n910575  -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n\n              hot  num_failed_logins  logged_in  num_compromised  ...  \\\n1537115 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n4657510 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n1894345 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n1649777 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n1634756 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n...           ...                ...        ...              ...  ...   \n2391255 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n2471385 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n2676542 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n1475808 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n910575  -0.026521          -0.004391  -0.409368        -0.002097  ...   \n\n         feature0  feature1  feature2  feature3  feature4   feature5  \\\n1537115  1.485163  0.573950       0.0  0.000000  0.336887   0.000000   \n4657510  0.000000  5.674854       0.0  5.825389  4.213655  14.140607   \n1894345  1.486886  0.573789       0.0  0.000000  0.336487   0.000000   \n1649777  1.485163  0.573950       0.0  0.000000  0.336887   0.000000   \n1634756  1.485163  0.573950       0.0  0.000000  0.336887   0.000000   \n...           ...       ...       ...       ...       ...        ...   \n2391255  1.485163  0.573950       0.0  0.000000  0.336887   0.000000   \n2471385  1.486886  0.573789       0.0  0.000000  0.336487   0.000000   \n2676542  1.485163  0.573950       0.0  0.000000  0.336887   0.000000   \n1475808  1.485163  0.573950       0.0  0.000000  0.336887   0.000000   \n910575   1.485163  0.573950       0.0  0.000000  0.336887   0.000000   \n\n         feature6  feature7  feature8  feature9  \n1537115  0.292402  0.501981  1.166986  0.499266  \n4657510  7.169546  5.212486  0.163113  1.542490  \n1894345  0.293716  0.501628  1.167947  0.499632  \n1649777  0.292402  0.501981  1.166986  0.499266  \n1634756  0.292402  0.501981  1.166986  0.499266  \n...           ...       ...       ...       ...  \n2391255  0.292402  0.501981  1.166986  0.499266  \n2471385  0.293716  0.501628  1.167947  0.499632  \n2676542  0.292402  0.501981  1.166986  0.499266  \n1475808  0.292402  0.501981  1.166986  0.499266  \n910575   0.292402  0.501981  1.166986  0.499266  \n\n[3281948 rows x 48 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>src_bytes</th>\n      <th>dst_bytes</th>\n      <th>land</th>\n      <th>wrong_fragment</th>\n      <th>urgent</th>\n      <th>hot</th>\n      <th>num_failed_logins</th>\n      <th>logged_in</th>\n      <th>num_compromised</th>\n      <th>...</th>\n      <th>feature0</th>\n      <th>feature1</th>\n      <th>feature2</th>\n      <th>feature3</th>\n      <th>feature4</th>\n      <th>feature5</th>\n      <th>feature6</th>\n      <th>feature7</th>\n      <th>feature8</th>\n      <th>feature9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1537115</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>1.485163</td>\n      <td>0.573950</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.336887</td>\n      <td>0.000000</td>\n      <td>0.292402</td>\n      <td>0.501981</td>\n      <td>1.166986</td>\n      <td>0.499266</td>\n    </tr>\n    <tr>\n      <th>4657510</th>\n      <td>-0.066833</td>\n      <td>-0.001949</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>5.674854</td>\n      <td>0.0</td>\n      <td>5.825389</td>\n      <td>4.213655</td>\n      <td>14.140607</td>\n      <td>7.169546</td>\n      <td>5.212486</td>\n      <td>0.163113</td>\n      <td>1.542490</td>\n    </tr>\n    <tr>\n      <th>1894345</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>1.486886</td>\n      <td>0.573789</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.336487</td>\n      <td>0.000000</td>\n      <td>0.293716</td>\n      <td>0.501628</td>\n      <td>1.167947</td>\n      <td>0.499632</td>\n    </tr>\n    <tr>\n      <th>1649777</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>1.485163</td>\n      <td>0.573950</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.336887</td>\n      <td>0.000000</td>\n      <td>0.292402</td>\n      <td>0.501981</td>\n      <td>1.166986</td>\n      <td>0.499266</td>\n    </tr>\n    <tr>\n      <th>1634756</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>1.485163</td>\n      <td>0.573950</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.336887</td>\n      <td>0.000000</td>\n      <td>0.292402</td>\n      <td>0.501981</td>\n      <td>1.166986</td>\n      <td>0.499266</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2391255</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>1.485163</td>\n      <td>0.573950</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.336887</td>\n      <td>0.000000</td>\n      <td>0.292402</td>\n      <td>0.501981</td>\n      <td>1.166986</td>\n      <td>0.499266</td>\n    </tr>\n    <tr>\n      <th>2471385</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>1.486886</td>\n      <td>0.573789</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.336487</td>\n      <td>0.000000</td>\n      <td>0.293716</td>\n      <td>0.501628</td>\n      <td>1.167947</td>\n      <td>0.499632</td>\n    </tr>\n    <tr>\n      <th>2676542</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>1.485163</td>\n      <td>0.573950</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.336887</td>\n      <td>0.000000</td>\n      <td>0.292402</td>\n      <td>0.501981</td>\n      <td>1.166986</td>\n      <td>0.499266</td>\n    </tr>\n    <tr>\n      <th>1475808</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>1.485163</td>\n      <td>0.573950</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.336887</td>\n      <td>0.000000</td>\n      <td>0.292402</td>\n      <td>0.501981</td>\n      <td>1.166986</td>\n      <td>0.499266</td>\n    </tr>\n    <tr>\n      <th>910575</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>1.485163</td>\n      <td>0.573950</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.336887</td>\n      <td>0.000000</td>\n      <td>0.292402</td>\n      <td>0.501981</td>\n      <td>1.166986</td>\n      <td>0.499266</td>\n    </tr>\n  </tbody>\n</table>\n<p>3281948 rows × 48 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(map(lambda x: 'feature' + str(x), range(10)))\n",
    "x_train_encoded = pd.DataFrame(data=encoder.predict(x_train), index=x_train.index, columns=columns)\n",
    "x_test_encoded = pd.DataFrame(data=encoder.predict(x_test), index=x_test.index, columns=columns)\n",
    "x_train_new_feature = x_train.merge(x_train_encoded, right_index=True, left_index=True)\n",
    "x_test_new_feature = x_test.merge(x_test_encoded, right_index=True, left_index=True)\n",
    "x_train_new_feature\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:57:15.760465Z",
     "start_time": "2023-07-18T00:56:14.348547Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satun/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.256004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's multi_error: 0.000353236\n"
     ]
    },
    {
     "data": {
      "text/plain": "0    1281322\n1     321171\n2      13465\n3        345\n4        180\ndtype: int64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(x_train_new_feature, y_train)\n",
    "lgb_eval = lgb.Dataset(x_test_new_feature, y_test, reference=lgb_train)\n",
    "\n",
    "# LightGBM parameters\n",
    "params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 5,\n",
    "        'metric': {'multi_error'}, # 評価指標 : 誤り率(= 1-正答率)  another multi_logloss\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 23,\n",
    "        'min_data_in_leaf': 1,\n",
    "        'num_iteration': 1000, #1000回学習\n",
    "        'verbose': 0\n",
    "}\n",
    "\n",
    "# モデルの学習\n",
    "model = lgb.train(params, # パラメータ\n",
    "            train_set=lgb_train, # トレーニングデータの指定\n",
    "            valid_sets=lgb_eval, # 検証データの指定\n",
    "            callbacks=[lgb.early_stopping(100)]\n",
    "               )\n",
    "\n",
    "# テストデータの予測 (クラス1の予測確率(クラス1である確率)を返す)\n",
    "y_pred_prob = model.predict(x_test_new_feature)\n",
    "# テストデータの予測 (予測クラス(0 or 1 or 2)を返す)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1) # 一番大きい予測確率のクラスを予測クラスに\n",
    "y_pred = pd.Series(y_pred)\n",
    "y_pred.value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:57:58.410558Z",
     "start_time": "2023-07-18T00:57:15.741632Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dos       1.00      1.00      1.00   1281513\n",
      "      normal       1.00      1.00      1.00    321018\n",
      "       probe       1.00      0.99      0.99     13564\n",
      "         r2l       0.95      0.89      0.92       371\n",
      "         u2r       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           1.00   1616483\n",
      "   macro avg       0.79      0.78      0.78   1616483\n",
      "weighted avg       1.00      1.00      1.00   1616483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=correspondences.keys()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:57:59.681014Z",
     "start_time": "2023-07-18T00:57:58.414601Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dos    TP: 1281287, TN: 334935, FP: 226, FN: 35\n",
      "normal    TP: 320878, TN: 1295172, FP: 140, FN: 293\n",
      "probe    TP: 13418, TN: 1602872, FP: 146, FN: 47\n",
      "r2l    TP: 329, TN: 1616096, FP: 42, FN: 16\n",
      "u2r    TP: 0, TN: 1616286, FP: 17, FN: 180\n"
     ]
    }
   ],
   "source": [
    "for key, confusion_matrix in zip(correspondences.keys(), multilabel_confusion_matrix(y_test, y_pred)):\n",
    "    print(f\"{key}    TP: {confusion_matrix[1][1]}, TN: {confusion_matrix[0][0]}, FP: {confusion_matrix[1][0]}, FN: {confusion_matrix[0][1]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:57:59.867141Z",
     "start_time": "2023-07-18T00:57:59.683458Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder1 (Dense)            (None, 10)                390       \n",
      "                                                                 \n",
      " encoder2 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                60        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 38)                418       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 923\n",
      "Trainable params: 923\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(units=10, activation='relu', input_dim=38, name='encoder1'),\n",
    "    Dense(units=5, activation='relu', name='encoder2'),\n",
    "    Dense(units=10, activation='relu'),\n",
    "    Dense(units=38, activation='relu'),\n",
    "])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T00:58:00.012257Z",
     "start_time": "2023-07-18T00:57:59.927861Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102561/102561 [==============================] - 118s 1ms/step - loss: 0.6666 - accuracy: 0.7483 - val_loss: 0.6441 - val_accuracy: 0.7767\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x15b9b36d0>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.fit(x_train, x_train,\n",
    "          epochs=1, # データセットを使って学習する回数\n",
    "        batch_size=32,\n",
    "        shuffle=True, # データをシャッフルすることで，．\n",
    "        validation_data=(x_train, x_train), # 評価用データ（検証データ）の指定\n",
    "        verbose=1,\n",
    "        use_multiprocessing=True\n",
    "          )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T01:00:01.124012Z",
     "start_time": "2023-07-18T00:58:00.012651Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "encoder = keras.Sequential([model.get_layer('encoder1'),\n",
    "                            model.get_layer('encoder2')])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T01:00:01.437091Z",
     "start_time": "2023-07-18T01:00:01.203820Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102561/102561 [==============================] - 23s 220us/step\n",
      "50516/50516 [==============================] - 12s 228us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "         duration  src_bytes  dst_bytes      land  wrong_fragment    urgent  \\\n1537115 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n4657510 -0.066833  -0.001949  -0.001696 -0.002391       -0.015139 -0.001103   \n1894345 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n1649777 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n1634756 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n...           ...        ...        ...       ...             ...       ...   \n2391255 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n2471385 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n2676542 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n1475808 -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n910575  -0.066833  -0.000853  -0.001696 -0.002391       -0.015139 -0.001103   \n\n              hot  num_failed_logins  logged_in  num_compromised  ...  \\\n1537115 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n4657510 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n1894345 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n1649777 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n1634756 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n...           ...                ...        ...              ...  ...   \n2391255 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n2471385 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n2676542 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n1475808 -0.026521          -0.004391  -0.409368        -0.002097  ...   \n910575  -0.026521          -0.004391  -0.409368        -0.002097  ...   \n\n         dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n1537115                    -0.156668             -0.466405   \n4657510                    -0.156668             -0.466405   \n1894345                    -0.156668             -0.466405   \n1649777                    -0.156668             -0.466405   \n1634756                    -0.156668             -0.466405   \n...                              ...                   ...   \n2391255                    -0.156668             -0.466405   \n2471385                    -0.156668             -0.466405   \n2676542                    -0.156668             -0.466405   \n1475808                    -0.156668             -0.466405   \n910575                     -0.156668             -0.466405   \n\n         dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n1537115                 -0.465454             -0.250832   \n4657510                 -0.465454              4.079245   \n1894345                 -0.465454             -0.250832   \n1649777                 -0.465454             -0.250832   \n1634756                 -0.465454             -0.250832   \n...                           ...                   ...   \n2391255                 -0.465454             -0.250832   \n2471385                 -0.465454             -0.250832   \n2676542                 -0.465454             -0.250832   \n1475808                 -0.465454             -0.250832   \n910575                  -0.465454             -0.250832   \n\n         dst_host_srv_rerror_rate   feature0  feature1  feature2  feature3  \\\n1537115                 -0.249632   0.000000  0.564129  3.360172  0.161625   \n4657510                  4.079791  12.364801  6.891846  8.588043  0.000000   \n1894345                 -0.249632   0.000000  0.564913  3.360382  0.160949   \n1649777                 -0.249632   0.000000  0.564129  3.360172  0.161625   \n1634756                 -0.249632   0.000000  0.564129  3.360172  0.161625   \n...                           ...        ...       ...       ...       ...   \n2391255                 -0.249632   0.000000  0.564129  3.360172  0.161625   \n2471385                 -0.249632   0.000000  0.564913  3.360383  0.160949   \n2676542                 -0.249632   0.000000  0.564129  3.360172  0.161625   \n1475808                 -0.249632   0.000000  0.564129  3.360172  0.161625   \n910575                  -0.249632   0.000000  0.564129  3.360172  0.161625   \n\n          feature4  \n1537115   2.288970  \n4657510  10.471345  \n1894345   2.289763  \n1649777   2.288970  \n1634756   2.288970  \n...            ...  \n2391255   2.288970  \n2471385   2.289763  \n2676542   2.288971  \n1475808   2.288971  \n910575    2.288971  \n\n[3281948 rows x 43 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>src_bytes</th>\n      <th>dst_bytes</th>\n      <th>land</th>\n      <th>wrong_fragment</th>\n      <th>urgent</th>\n      <th>hot</th>\n      <th>num_failed_logins</th>\n      <th>logged_in</th>\n      <th>num_compromised</th>\n      <th>...</th>\n      <th>dst_host_srv_diff_host_rate</th>\n      <th>dst_host_serror_rate</th>\n      <th>dst_host_srv_serror_rate</th>\n      <th>dst_host_rerror_rate</th>\n      <th>dst_host_srv_rerror_rate</th>\n      <th>feature0</th>\n      <th>feature1</th>\n      <th>feature2</th>\n      <th>feature3</th>\n      <th>feature4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1537115</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>-0.156668</td>\n      <td>-0.466405</td>\n      <td>-0.465454</td>\n      <td>-0.250832</td>\n      <td>-0.249632</td>\n      <td>0.000000</td>\n      <td>0.564129</td>\n      <td>3.360172</td>\n      <td>0.161625</td>\n      <td>2.288970</td>\n    </tr>\n    <tr>\n      <th>4657510</th>\n      <td>-0.066833</td>\n      <td>-0.001949</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>-0.156668</td>\n      <td>-0.466405</td>\n      <td>-0.465454</td>\n      <td>4.079245</td>\n      <td>4.079791</td>\n      <td>12.364801</td>\n      <td>6.891846</td>\n      <td>8.588043</td>\n      <td>0.000000</td>\n      <td>10.471345</td>\n    </tr>\n    <tr>\n      <th>1894345</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>-0.156668</td>\n      <td>-0.466405</td>\n      <td>-0.465454</td>\n      <td>-0.250832</td>\n      <td>-0.249632</td>\n      <td>0.000000</td>\n      <td>0.564913</td>\n      <td>3.360382</td>\n      <td>0.160949</td>\n      <td>2.289763</td>\n    </tr>\n    <tr>\n      <th>1649777</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>-0.156668</td>\n      <td>-0.466405</td>\n      <td>-0.465454</td>\n      <td>-0.250832</td>\n      <td>-0.249632</td>\n      <td>0.000000</td>\n      <td>0.564129</td>\n      <td>3.360172</td>\n      <td>0.161625</td>\n      <td>2.288970</td>\n    </tr>\n    <tr>\n      <th>1634756</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>-0.156668</td>\n      <td>-0.466405</td>\n      <td>-0.465454</td>\n      <td>-0.250832</td>\n      <td>-0.249632</td>\n      <td>0.000000</td>\n      <td>0.564129</td>\n      <td>3.360172</td>\n      <td>0.161625</td>\n      <td>2.288970</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2391255</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>-0.156668</td>\n      <td>-0.466405</td>\n      <td>-0.465454</td>\n      <td>-0.250832</td>\n      <td>-0.249632</td>\n      <td>0.000000</td>\n      <td>0.564129</td>\n      <td>3.360172</td>\n      <td>0.161625</td>\n      <td>2.288970</td>\n    </tr>\n    <tr>\n      <th>2471385</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>-0.156668</td>\n      <td>-0.466405</td>\n      <td>-0.465454</td>\n      <td>-0.250832</td>\n      <td>-0.249632</td>\n      <td>0.000000</td>\n      <td>0.564913</td>\n      <td>3.360383</td>\n      <td>0.160949</td>\n      <td>2.289763</td>\n    </tr>\n    <tr>\n      <th>2676542</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>-0.156668</td>\n      <td>-0.466405</td>\n      <td>-0.465454</td>\n      <td>-0.250832</td>\n      <td>-0.249632</td>\n      <td>0.000000</td>\n      <td>0.564129</td>\n      <td>3.360172</td>\n      <td>0.161625</td>\n      <td>2.288971</td>\n    </tr>\n    <tr>\n      <th>1475808</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>-0.156668</td>\n      <td>-0.466405</td>\n      <td>-0.465454</td>\n      <td>-0.250832</td>\n      <td>-0.249632</td>\n      <td>0.000000</td>\n      <td>0.564129</td>\n      <td>3.360172</td>\n      <td>0.161625</td>\n      <td>2.288971</td>\n    </tr>\n    <tr>\n      <th>910575</th>\n      <td>-0.066833</td>\n      <td>-0.000853</td>\n      <td>-0.001696</td>\n      <td>-0.002391</td>\n      <td>-0.015139</td>\n      <td>-0.001103</td>\n      <td>-0.026521</td>\n      <td>-0.004391</td>\n      <td>-0.409368</td>\n      <td>-0.002097</td>\n      <td>...</td>\n      <td>-0.156668</td>\n      <td>-0.466405</td>\n      <td>-0.465454</td>\n      <td>-0.250832</td>\n      <td>-0.249632</td>\n      <td>0.000000</td>\n      <td>0.564129</td>\n      <td>3.360172</td>\n      <td>0.161625</td>\n      <td>2.288971</td>\n    </tr>\n  </tbody>\n</table>\n<p>3281948 rows × 43 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(map(lambda x: 'feature' + str(x), range(5)))\n",
    "x_train_encoded = pd.DataFrame(data=encoder.predict(x_train), index=x_train.index, columns=columns)\n",
    "x_test_encoded = pd.DataFrame(data=encoder.predict(x_test), index=x_test.index, columns=columns)\n",
    "x_train_new_feature = x_train.merge(x_train_encoded, right_index=True, left_index=True)\n",
    "x_test_new_feature = x_test.merge(x_test_encoded, right_index=True, left_index=True)\n",
    "x_train_new_feature\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T01:00:55.994589Z",
     "start_time": "2023-07-18T01:00:01.254169Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satun/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.153446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's multi_error: 0.000322923\n"
     ]
    },
    {
     "data": {
      "text/plain": "0    1281300\n1     321360\n2      13454\n3        367\n4          2\ndtype: int64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(x_train_new_feature, y_train)\n",
    "lgb_eval = lgb.Dataset(x_test_new_feature, y_test, reference=lgb_train)\n",
    "# モデルの学習\n",
    "model = lgb.train(params, # パラメータ\n",
    "            train_set=lgb_train, # トレーニングデータの指定\n",
    "            valid_sets=lgb_eval, # 検証データの指定\n",
    "            callbacks=[lgb.early_stopping(100)]\n",
    "               )\n",
    "\n",
    "# テストデータの予測 (クラス1の予測確率(クラス1である確率)を返す)\n",
    "y_pred_prob = model.predict(x_test_new_feature)\n",
    "# テストデータの予測 (予測クラス(0 or 1 or 2)を返す)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1) # 一番大きい予測確率のクラスを予測クラスに\n",
    "y_pred = pd.Series(y_pred)\n",
    "y_pred.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T01:01:37.280039Z",
     "start_time": "2023-07-18T01:00:55.993632Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dos       1.00      1.00      1.00   1281513\n",
      "      normal       1.00      1.00      1.00    321018\n",
      "       probe       1.00      0.99      0.99     13564\n",
      "         r2l       0.92      0.91      0.92       371\n",
      "         u2r       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           1.00   1616483\n",
      "   macro avg       0.78      0.78      0.78   1616483\n",
      "weighted avg       1.00      1.00      1.00   1616483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=correspondences.keys()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T01:01:38.557355Z",
     "start_time": "2023-07-18T01:01:37.284479Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dos    TP: 1281282, TN: 334952, FP: 231, FN: 18\n",
      "normal    TP: 320938, TN: 1295043, FP: 80, FN: 422\n",
      "probe    TP: 13402, TN: 1602867, FP: 162, FN: 52\n",
      "r2l    TP: 339, TN: 1616084, FP: 32, FN: 28\n",
      "u2r    TP: 0, TN: 1616464, FP: 17, FN: 2\n"
     ]
    }
   ],
   "source": [
    "for key, confusion_matrix in zip(correspondences.keys(), multilabel_confusion_matrix(y_test, y_pred)):\n",
    "    print(f\"{key}    TP: {confusion_matrix[1][1]}, TN: {confusion_matrix[0][0]}, FP: {confusion_matrix[1][0]}, FN: {confusion_matrix[0][1]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T01:24:17.361216Z",
     "start_time": "2023-07-18T01:24:17.135136Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 10％データを使用した場合\n",
    "## 数値入力データのみ（38次元）の場合\n",
    "dos    TP: 129147, TN: 33829, FP: 34, FN: 17\n",
    "normal TP: 32045,  TN: 130870, FP: 57, FN: 55\n",
    "probe  TP: 1338,   TN: 161666, FP: 17, FN: 6\n",
    "r2l    TP: 353,    TN: 162637, FP: 19, FN: 18\n",
    "u2r    TP: 5,      TN: 162967, FP: 12, FN: 43\n",
    "\n",
    "\n",
    "## 数値入力データ+AEで学習した特徴量(10次元)（48次元）の場合\n",
    "dos    TP: 129168, TN: 33813,  FP: 13, FN: 33\n",
    "normal TP: 32001,  TN: 130864, FP: 101, FN: 61\n",
    "probe  TP: 1334,   TN: 161658, FP: 21, FN: 14\n",
    "r2l    TP: 342,    TN: 162630, FP: 30, FN: 25\n",
    "u2r    TP: 4,      TN: 162965, FP: 13, FN: 45\n",
    "\n",
    "## 数値入力データ+AEで学習した特徴量(5次元)（43次元）の場合\n",
    "dos    TP: 129173, TN: 33781, FP: 8, FN: 65\n",
    "normal    TP: 32018, TN: 130880, FP: 84, FN: 45\n",
    "probe    TP: 1324, TN: 161659, FP: 31, FN: 13\n",
    "r2l    TP: 349, TN: 162622, FP: 23, FN: 33\n",
    "u2r    TP: 1, TN: 163004, FP: 16, FN: 6\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T01:01:38.748419Z",
     "start_time": "2023-07-18T01:01:38.747015Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
