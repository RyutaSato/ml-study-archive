{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T14:27:35.444217900Z",
     "start_time": "2023-10-29T14:27:35.426214600Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import platform\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T14:36:54.887456500Z",
     "start_time": "2023-10-29T14:36:54.879459400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "\n",
    "\n",
    "\n",
    "from calendar import EPOCH\n",
    "\n",
    "\n",
    "ROOT_DIR = os.path.join(os.getcwd(), \"..\")\n",
    "USE_FULLDATA = False\n",
    "RESTRECTED_FEATURES = False\n",
    "RANDOM_SEED = 2023\n",
    "N_SPLITS= 4\n",
    "ACTIVATION = 'relu'\n",
    "ENCODER_SIZES = [10, 5]\n",
    "Model_type = 'LogisticRegression'\n",
    "\n",
    "# AutoEncoder\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 使用する機械学習モデル\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "params = {\n",
    "    'penalty': 'l2',\n",
    "    'solver': 'lbfgs',\n",
    "    'random_state': RANDOM_SEED,\n",
    "    'max_iter': 10\n",
    "}\n",
    "Model = LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T14:27:35.490721500Z",
     "start_time": "2023-10-29T14:27:35.476725400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT DIRECTORY:  D:\\ml-study-archive-rsato\\experiments\\..\n",
      "USE:  10% data\n",
      "ran:  2023-10-29 23:27:35.475727\n",
      "python:      3.10.5\n",
      "sklearn:     1.2.2\n",
      "tensorflow:  2.13.0-rc0\n",
      "keras:       2.13.1rc0\n",
      "numpy:       1.23.5\n",
      "pandas:      1.5.3\n"
     ]
    }
   ],
   "source": [
    "print(\"ROOT DIRECTORY: \", ROOT_DIR)\n",
    "print(\"USE: \", \"Full data\" if USE_FULLDATA else \"10% data\")\n",
    "print(\"ran: \", datetime.datetime.now())\n",
    "print(f\"python:      {platform.python_version()}\")\n",
    "print(f\"sklearn:     {sklearn.__version__}\")\n",
    "print(f\"tensorflow:  {tf.__version__}\")\n",
    "print(f\"keras:       {keras.__version__}\")\n",
    "print(f\"numpy:       {np.__version__}\")\n",
    "print(f\"pandas:      {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T14:27:37.372207Z",
     "start_time": "2023-10-29T14:27:35.494721800Z"
    }
   },
   "outputs": [],
   "source": [
    "# KDD'99 ラベルデータの読み込み\n",
    "with open(ROOT_DIR + \"/datasets/kddcup.names\", \"r\") as f:\n",
    "        # 一行目は不要なので無視\n",
    "    _ = f.readline()\n",
    "    # `:`より手前がラベルなので，その部分を抽出してリストに追加\n",
    "    names = [line.split(':')[0] for line in f]\n",
    "# 　正解ラベルを追加\n",
    "names.append(\"true_label\")\n",
    "\n",
    "# KDD'99 クラスラベルデータの読み込み\n",
    "with open(ROOT_DIR + \"/datasets/training_attack_types\", \"r\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    classes = {'normal': 'normal'}\n",
    "    for line in lines:\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        k, v = tuple(line.split(\" \"))\n",
    "        classes[k] = v\n",
    "\n",
    "# 除外する特徴量のリスト\n",
    "ignore_names = [\n",
    "    \"hot\", \"num_compromised\", \"num_file_creations\",      \n",
    "    \"num_outbound_cmds\", \"is_host_login\", \"srv_count\",\n",
    "    \"srv_serror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_diff_srv_rate\"\n",
    "    ]\n",
    "\n",
    "# KDD'99 データの読み込み\n",
    "if USE_FULLDATA:\n",
    "    df = pd.read_csv(ROOT_DIR + \"/datasets/kddcup.data\", names=names, index_col=False)\n",
    "else:\n",
    "    df = pd.read_csv(ROOT_DIR + \"/datasets/kddcup.data_10_percent\", names=names, index_col=False)\n",
    "\n",
    "# カテゴリー特徴量を削除\n",
    "data_x: pd.DataFrame = df.copy().drop(columns=['protocol_type', 'service', 'flag'], axis=1)\n",
    "\n",
    "# 除外する特徴量を削除\n",
    "if RESTRECTED_FEATURES:\n",
    "    data_x = data_x.drop(columns=ignore_names, axis=1)\n",
    "\n",
    "\n",
    "# ラベルデータを切り分ける\n",
    "data_y = data_x.pop(\"true_label\").map(lambda x: x.replace('.', ''))\n",
    " \n",
    "# namesを更新\n",
    "names = data_x.columns\n",
    "\n",
    " # 正規化\n",
    "data_x = pd.DataFrame(StandardScaler().fit_transform(data_x), columns=names)\n",
    "\n",
    "# ラベルを変換\n",
    "data_y = data_y.map(lambda x: classes[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T14:27:37.388205900Z",
     "start_time": "2023-10-29T14:27:37.372207Z"
    }
   },
   "outputs": [],
   "source": [
    "# k分割\n",
    "k_fold = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T14:28:49.954446400Z",
     "start_time": "2023-10-29T14:27:37.391204600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder0 (Dense)            (None, 10)                390       \n",
      "                                                                 \n",
      " encoder1 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                60        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 38)                418       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 923 (3.61 KB)\n",
      "Trainable params: 923 (3.61 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "15439/15439 [==============================] - 12s 737us/step - loss: 0.6355\n",
      "Epoch 2/5\n",
      "15439/15439 [==============================] - 12s 797us/step - loss: 0.6011\n",
      "Epoch 3/5\n",
      "15439/15439 [==============================] - 11s 741us/step - loss: 0.6007\n",
      "Epoch 4/5\n",
      "15439/15439 [==============================] - 11s 721us/step - loss: 0.5826\n",
      "Epoch 5/5\n",
      "15439/15439 [==============================] - 11s 719us/step - loss: 0.5784\n",
      "15439/15439 [==============================] - 8s 514us/step\n"
     ]
    }
   ],
   "source": [
    "def generate_encoder(x: pd.DataFrame):\n",
    "    _model = keras.Sequential( \n",
    "        [\n",
    "            Dense(ENCODER_SIZES[0], activation=ACTIVATION, input_shape=(x.shape[1],), name=\"encoder0\"),\n",
    "            *[\n",
    "                Dense(hidden_layer_size, activation=ACTIVATION, name=f\"encoder{idx + 1}\")\n",
    "                for idx, hidden_layer_size in enumerate(ENCODER_SIZES[1:])\n",
    "            ],\n",
    "            *[\n",
    "                Dense(hidden_layer_size, activation=ACTIVATION)\n",
    "                for hidden_layer_size in ENCODER_SIZES[-2::-1]\n",
    "            ],\n",
    "            Dense(x.shape[1], activation=ACTIVATION),\n",
    "        ]\n",
    "    )\n",
    "    _model.summary()\n",
    "    _model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    _model.fit(x, x, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    return keras.Sequential(_model.layers[: len(ENCODER_SIZES)])\n",
    "\n",
    "encoder = generate_encoder(data_x)\n",
    "new_features = pd.DataFrame(encoder.predict(data_x),\n",
    "columns=[f\"ae_{idx}\" for idx in range(ENCODER_SIZES[-1])])\n",
    "# データを結合\n",
    "data_x_ae = pd.concat([data_x, new_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T14:28:49.969444600Z",
     "start_time": "2023-10-29T14:28:49.954446400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((494021, 38), (494021, 43))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape, data_x_ae.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T14:28:50.014965400Z",
     "start_time": "2023-10-29T14:28:49.972445200Z"
    }
   },
   "outputs": [],
   "source": [
    "results_default = dict()\n",
    "results_ae = dict()\n",
    "\n",
    "\n",
    "def predict(_x, _y):\n",
    "    _generator = k_fold.split(_x, _y)\n",
    "    accuracies = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(_generator):\n",
    "        print(f\"fold: {fold}\")\n",
    "        # データを分割\n",
    "        x_train = _x.iloc[train_idx]\n",
    "        y_train = _y.iloc[train_idx]\n",
    "        x_test = _x.iloc[test_idx]\n",
    "        y_test = _y.iloc[test_idx]\n",
    "\n",
    "        # モデルを学習\n",
    "        model = Model(**params)\n",
    "        model.fit(x_train, y_train)\n",
    "        # テストデータで評価\n",
    "        accuracy = classification_report(y_test, model.predict(x_test), output_dict=True)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"accuracy: {accuracy['macro avg']['recall']}\") # type: ignore\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T14:29:20.206902600Z",
     "start_time": "2023-10-29T14:28:49.992450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "accuracy: 0.7207328405557556\n",
      "fold: 1\n",
      "accuracy: 0.7414721330838735\n",
      "fold: 2\n",
      "accuracy: 0.7616946771778198\n",
      "fold: 3\n",
      "accuracy: 0.7679793235349159\n",
      "fold: 0\n",
      "accuracy: 0.6193339615226862\n",
      "fold: 1\n",
      "accuracy: 0.6660122396166361\n",
      "fold: 2\n",
      "accuracy: 0.5651071753340396\n",
      "fold: 3\n",
      "accuracy: 0.700306768812134\n"
     ]
    }
   ],
   "source": [
    "# 元の特徴量のみで学習\n",
    "results_default = predict(data_x, data_y)\n",
    "\n",
    "# AE特徴量を追加して学習\n",
    "results_ae = predict(data_x_ae, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T16:02:20.176802700Z",
     "start_time": "2023-10-29T16:02:20.162804200Z"
    }
   },
   "outputs": [],
   "source": [
    "results = dict()\n",
    "results['config'] = {\n",
    "    'USE_FULLDATA': USE_FULLDATA,\n",
    "    'RESTRECTED_FEATURES': RESTRECTED_FEATURES,\n",
    "    'RANDOM_SEED': RANDOM_SEED,\n",
    "    'N_SPLITS': N_SPLITS,\n",
    "    'Date': datetime.datetime.now().__str__(),\n",
    "    'ACTIVATION': ACTIVATION,\n",
    "    'ENCODER_SIZES': ENCODER_SIZES,\n",
    "    'EPOCHS': EPOCHS,\n",
    "    'BATCH_SIZE': BATCH_SIZE,\n",
    "    'Model': Model_type,\n",
    "    'params': params\n",
    "}\n",
    "results['default'] = dict()\n",
    "for k0 in ['default', 'ae']:\n",
    "    results[k0] = dict()\n",
    "    for k1 in results_default[0].keys():\n",
    "        results[k0][k1] = dict()\n",
    "        if not hasattr(results_default[0][k1], 'keys'):\n",
    "            continue\n",
    "        for k2 in results_default[0][k1].keys():\n",
    "            results[k0][k1][k2] = np.mean([results_default[i][k1][k2] for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T16:02:20.743395800Z",
     "start_time": "2023-10-29T16:02:20.728395800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'config': {'USE_FULLDATA': False,\n  'RESTRECTED_FEATURES': False,\n  'RANDOM_SEED': 2023,\n  'N_SPLITS': 4,\n  'Date': '2023-10-30 01:02:20.161794',\n  'ACTIVATION': 'relu',\n  'ENCODER_SIZES': [10, 5],\n  'EPOCHS': 5,\n  'BATCH_SIZE': 32,\n  'Model': 'LogisticRegression',\n  'params': {'penalty': 'l2',\n   'solver': 'lbfgs',\n   'random_state': 2023,\n   'max_iter': 10}},\n 'default': {'dos': {'precision': 0.9983640610875981,\n   'recall': 0.9972640807933347,\n   'f1-score': 0.9978124117242654,\n   'support': 97864.5},\n  'normal': {'precision': 0.9823062010811222,\n   'recall': 0.9894837511984348,\n   'f1-score': 0.9858524051653282,\n   'support': 24319.5},\n  'probe': {'precision': 0.8757492902557835,\n   'recall': 0.847825808435402,\n   'f1-score': 0.861508336547864,\n   'support': 1026.75},\n  'r2l': {'precision': 0.618676891001053,\n   'recall': 0.5398904621286691,\n   'f1-score': 0.5732038873506753,\n   'support': 281.5},\n  'u2r': {'precision': 0.7642857142857143,\n   'recall': 0.3653846153846154,\n   'f1-score': 0.47487128146453084,\n   'support': 13.0},\n  'accuracy': {},\n  'macro avg': {'precision': 0.8478764315422542,\n   'recall': 0.7479697435880912,\n   'f1-score': 0.7786496644505327,\n   'support': 123505.25},\n  'weighted avg': {'precision': 0.993292780558574,\n   'recall': 0.9933808458961415,\n   'f1-score': 0.993301480957217,\n   'support': 123505.25}},\n 'ae': {'dos': {'precision': 0.9983640610875981,\n   'recall': 0.9972640807933347,\n   'f1-score': 0.9978124117242654,\n   'support': 97864.5},\n  'normal': {'precision': 0.9823062010811222,\n   'recall': 0.9894837511984348,\n   'f1-score': 0.9858524051653282,\n   'support': 24319.5},\n  'probe': {'precision': 0.8757492902557835,\n   'recall': 0.847825808435402,\n   'f1-score': 0.861508336547864,\n   'support': 1026.75},\n  'r2l': {'precision': 0.618676891001053,\n   'recall': 0.5398904621286691,\n   'f1-score': 0.5732038873506753,\n   'support': 281.5},\n  'u2r': {'precision': 0.7642857142857143,\n   'recall': 0.3653846153846154,\n   'f1-score': 0.47487128146453084,\n   'support': 13.0},\n  'accuracy': {},\n  'macro avg': {'precision': 0.8478764315422542,\n   'recall': 0.7479697435880912,\n   'f1-score': 0.7786496644505327,\n   'support': 123505.25},\n  'weighted avg': {'precision': 0.993292780558574,\n   'recall': 0.9933808458961415,\n   'f1-score': 0.993301480957217,\n   'support': 123505.25}}}"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-29T14:29:20.318425500Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-29T14:29:20.319426600Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
