{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rsato/ml/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import platform\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "\n",
    "\n",
    "\n",
    "from calendar import EPOCH\n",
    "\n",
    "\n",
    "ROOT_DIR = os.path.join(os.getcwd(), \"..\")\n",
    "USE_FULLDATA = False\n",
    "RESTRECTED_FEATURES = False\n",
    "RANDOM_SEED = 2023\n",
    "N_SPLITS= 4\n",
    "ACTIVATION = 'relu'\n",
    "ENCODER_SIZES = [10, 5]\n",
    "\n",
    "# AutoEncoder\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 使用する機械学習モデル\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "params = {\n",
    "    'penalty': 'l2',\n",
    "    'solver': 'lbfgs',\n",
    "    'random_state': RANDOM_SEED,\n",
    "    'max_iter': 10\n",
    "}\n",
    "Model = LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT DIRECTORY:  /Users/rsato/ml/experiments/..\n",
      "USE:  10% data\n",
      "ran:  2023-10-27 15:07:55.526160\n",
      "python:      3.9.6\n",
      "sklearn:     1.3.1\n",
      "tensorflow:  2.14.0\n",
      "keras:       2.14.0\n",
      "numpy:       1.26.1\n",
      "pandas:      2.1.1\n"
     ]
    }
   ],
   "source": [
    "print(\"ROOT DIRECTORY: \", ROOT_DIR)\n",
    "print(\"USE: \", \"Full data\" if USE_FULLDATA else \"10% data\")\n",
    "print(\"ran: \", datetime.datetime.now())\n",
    "print(f\"python:      {platform.python_version()}\")\n",
    "print(f\"sklearn:     {sklearn.__version__}\")\n",
    "print(f\"tensorflow:  {tf.__version__}\")\n",
    "print(f\"keras:       {keras.__version__}\")\n",
    "print(f\"numpy:       {np.__version__}\")\n",
    "print(f\"pandas:      {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDD'99 ラベルデータの読み込み\n",
    "with open(ROOT_DIR + \"/datasets/kddcup.names\", \"r\") as f:\n",
    "        # 一行目は不要なので無視\n",
    "    _ = f.readline()\n",
    "    # `:`より手前がラベルなので，その部分を抽出してリストに追加\n",
    "    names = [line.split(':')[0] for line in f]\n",
    "# 　正解ラベルを追加\n",
    "names.append(\"true_label\")\n",
    "\n",
    "# KDD'99 クラスラベルデータの読み込み\n",
    "with open(ROOT_DIR + \"/datasets/training_attack_types\", \"r\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    classes = {'normal': 'normal'}\n",
    "    for line in lines:\n",
    "        k, v = tuple(line.split(\" \"))\n",
    "        classes[k] = v\n",
    "\n",
    "# 除外する特徴量のリスト\n",
    "ignore_names = [\n",
    "    \"hot\", \"num_compromised\", \"num_file_creations\",      \n",
    "    \"num_outbound_cmds\", \"is_host_login\", \"srv_count\",\n",
    "    \"srv_serror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_diff_srv_rate\"\n",
    "    ]\n",
    "\n",
    "# KDD'99 データの読み込み\n",
    "if USE_FULLDATA:\n",
    "    df = pd.read_csv(ROOT_DIR + \"/datasets/kddcup.data\", names=names, index_col=False)\n",
    "else:\n",
    "    df = pd.read_csv(ROOT_DIR + \"/datasets/kddcup.data_10_percent\", names=names, index_col=False)\n",
    "\n",
    "# カテゴリー特徴量を削除\n",
    "data_x: pd.DataFrame = df.copy().drop(columns=['protocol_type', 'service', 'flag'], axis=1)\n",
    "\n",
    "# 除外する特徴量を削除\n",
    "if RESTRECTED_FEATURES:\n",
    "    data_x = data_x.drop(columns=ignore_names, axis=1)\n",
    "\n",
    "\n",
    "# ラベルデータを切り分ける\n",
    "data_y = data_x.pop(\"true_label\").map(lambda x: x.replace('.', ''))\n",
    " \n",
    "# namesを更新\n",
    "names = data_x.columns\n",
    "\n",
    " # 正規化\n",
    "data_x = pd.DataFrame(StandardScaler().fit_transform(data_x), columns=names)\n",
    "\n",
    "# ラベルを変換\n",
    "data_y = data_y.map(lambda x: classes[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k分割\n",
    "k_fold = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder0 (Dense)            (None, 10)                390       \n",
      "                                                                 \n",
      " encoder1 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                60        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 38)                418       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 923 (3.61 KB)\n",
      "Trainable params: 923 (3.61 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "15439/15439 [==============================] - 8s 503us/step - loss: 0.7105\n",
      "Epoch 2/5\n",
      "15439/15439 [==============================] - 8s 500us/step - loss: 0.6965\n",
      "Epoch 3/5\n",
      "15439/15439 [==============================] - 8s 496us/step - loss: 0.6867\n",
      "Epoch 4/5\n",
      "15439/15439 [==============================] - 8s 500us/step - loss: 0.6533\n",
      "Epoch 5/5\n",
      "15439/15439 [==============================] - 8s 497us/step - loss: 0.6527\n",
      "15439/15439 [==============================] - 5s 296us/step\n"
     ]
    }
   ],
   "source": [
    "def generate_encoder(x: pd.DataFrame):\n",
    "    _model = keras.Sequential( \n",
    "        [\n",
    "            Dense(ENCODER_SIZES[0], activation=ACTIVATION, input_shape=(x.shape[1],), name=\"encoder0\"),\n",
    "            *[\n",
    "                Dense(hidden_layer_size, activation=ACTIVATION, name=f\"encoder{idx + 1}\")\n",
    "                for idx, hidden_layer_size in enumerate(ENCODER_SIZES[1:])\n",
    "            ],\n",
    "            *[\n",
    "                Dense(hidden_layer_size, activation=ACTIVATION)\n",
    "                for hidden_layer_size in ENCODER_SIZES[-2::-1]\n",
    "            ],\n",
    "            Dense(x.shape[1], activation=ACTIVATION),\n",
    "        ]\n",
    "    )\n",
    "    _model.summary()\n",
    "    _model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    _model.fit(x, x, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    return keras.Sequential(_model.layers[: len(ENCODER_SIZES)])\n",
    "\n",
    "encoder = generate_encoder(data_x)\n",
    "new_features = pd.DataFrame(encoder.predict(data_x),\n",
    "columns=[f\"ae_{idx}\" for idx in range(ENCODER_SIZES[-1])])\n",
    "# データを結合\n",
    "data_x_ae = pd.concat([data_x, new_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((494021, 38), (494021, 43))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape, data_x_ae.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_default = dict()\n",
    "results_ae = dict()\n",
    "\n",
    "\n",
    "def predict(_x, _y):\n",
    "    _generator = k_fold.split(_x, _y)\n",
    "    accuracies = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(_generator):\n",
    "        print(f\"fold: {fold}\")\n",
    "        # データを分割\n",
    "        x_train = _x.iloc[train_idx]\n",
    "        y_train = _y.iloc[train_idx]\n",
    "        x_test = _x.iloc[test_idx]\n",
    "        y_test = _y.iloc[test_idx]\n",
    "\n",
    "        # モデルを学習\n",
    "        model = Model(**params)\n",
    "        model.fit(x_train, y_train)\n",
    "        # テストデータで評価\n",
    "        accuracy = classification_report(y_test, model.predict(x_test), output_dict=True)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"accuracy: {accuracy['macro avg']['recall']}\") # type: ignore\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "accuracy: 0.7207328405557556\n",
      "fold: 1\n",
      "accuracy: 0.7414721330838735\n",
      "fold: 2\n",
      "accuracy: 0.7616946771778198\n",
      "fold: 3\n",
      "accuracy: 0.7679793235349159\n",
      "fold: 0\n",
      "accuracy: 0.5960661003168634\n",
      "fold: 1\n",
      "accuracy: 0.6919568114318806\n",
      "fold: 2\n",
      "accuracy: 0.6789443601389913\n",
      "fold: 3\n",
      "accuracy: 0.6359807513441922\n"
     ]
    }
   ],
   "source": [
    "# 元の特徴量のみで学習\n",
    "results_default = predict(data_x, data_y)\n",
    "\n",
    "# AE特徴量を追加して学習\n",
    "results_ae = predict(data_x_ae, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47487128146453084"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.mean([results_default[i]['u2r'][\"f1-score\"] for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4752527871402644"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([results_ae[i]['u2r'][\"f1-score\"] for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
